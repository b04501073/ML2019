{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    f = 1. / (1. + np.exp(-z))\n",
    "    bound = 1e-8\n",
    "    return np.clip(f, bound, 1-bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fpath = \"data/X_train\"\n",
    "Y_train_fpath = \"data/Y_train\"\n",
    "train_x = np.genfromtxt(X_train_fpath, delimiter=',', skip_header=1)\n",
    "train_y = np.genfromtxt(Y_train_fpath, delimiter=',', skip_header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.zeros(shape = (len(train_x[0]),1))\n",
    "lr_w = np.zeros((len(train_x[0]), 1))\n",
    "iteration = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 123)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t = np.transpose(train_x)\n",
    "\n",
    "feature_size = len(train_x[0])\n",
    "train_data_size = len(train_x)\n",
    "\n",
    "mean1_star = np.zeros((feature_size,))\n",
    "mean2_star = np.zeros((feature_size,))\n",
    "sigma1_star = np.zeros((feature_size, feature_size))\n",
    "sigma2_star = np.zeros((feature_size, feature_size))\n",
    "\n",
    "count_1 = 0\n",
    "count_2 = 0\n",
    "\n",
    "for i in range(train_data_size):\n",
    "    if train_y[i] == 1:\n",
    "        count_1 += 1\n",
    "        mean1_star += train_x[i]\n",
    "    else:\n",
    "        count_2 += 1\n",
    "        mean2_star += train_x[i]\n",
    "mean1_star = mean1_star / count_1\n",
    "mean2_star = mean2_star / count_2\n",
    "for i in range(train_data_size):\n",
    "    if train_y[i] == 1:\n",
    "        sigma1_star += np.dot(np.transpose([train_x[i] - mean1_star]), [train_x[i] - mean1_star])\n",
    "    else:\n",
    "        sigma2_star += np.dot(np.transpose([train_x[i] - mean2_star]), [train_x[i] - mean2_star])\n",
    "        \n",
    "sigma1_star /= count_1\n",
    "sigma2_star /= count_2\n",
    "shared_sigma = (float(count_1) / train_data_size) * sigma1_star + (float(count_2) / train_data_size) * sigma2_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxlee/.conda/envs/n_tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "inv_size = len(shared_sigma)\n",
    "i = np.eye(inv_size,inv_size)\n",
    "sigma_inverse = np.linalg.lstsq(shared_sigma, i)[0]\n",
    "\n",
    "w = np.dot((mean1_star - mean2_star), sigma_inverse)\n",
    "b =(-0.5) * np.dot(np.dot(mean1_star, sigma_inverse), mean1_star) \\\n",
    "    + (0.5) * np.dot(np.dot(mean2_star, sigma_inverse), mean2_star) \\\n",
    "    + np.log(count_1/count_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8421731519302232\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "count = 0;\n",
    "train_x_t = train_x.T\n",
    "train_y_pred = sigmoid(np.dot(w, train_x_t) + b)\n",
    "\n",
    "for i in range(len(train_y_pred)):\n",
    "    if(train_y_pred[i] > 0.5 and train_y[i] == 1):\n",
    "        count += 1\n",
    "    elif(train_y_pred[i] < 0.5 and train_y[i] == 0):\n",
    "        count += 1\n",
    "print(float(count) / len(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = np.load(\"test_x.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict\n",
    "x = test_x.T\n",
    "a = np.dot(w, x) + b\n",
    "test_y = sigmoid(a)\n",
    "test_y_out = []\n",
    "for i in test_y:\n",
    "    if i < 0.5:\n",
    "        test_y_out.append('0')\n",
    "    else:\n",
    "        test_y_out.append('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = open(\"hw2_generative_1\", 'w', newline='')\n",
    "writer = csv.writer(output)\n",
    "writer.writerow(['id', 'label'])\n",
    "for i in range(len(test_y_out)):\n",
    "    writer.writerow([str(i+1), test_y_out[i]])\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
